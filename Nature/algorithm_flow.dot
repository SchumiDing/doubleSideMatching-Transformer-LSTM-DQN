digraph "Algorithm Flow" {
	graph [nodesep=0.5 rankdir=LR splines=ortho]
	node [fillcolor="#F0F8FF" shape=record style=filled]
	input [label=<
<table border="0" cellborder="0">
  <tr><td bgcolor="#FFE4B5" colspan="2"><b>Input Matrix</b></td></tr>
  <tr>
    <td align="left">Tasks</td>
    <td align="right">Providers</td>
  </tr>
  <tr>
    <td colspan="2" border="1" cellpadding="5">(task_num × provider_num)</td>
  </tr>
</table>>]
	subgraph cluster_attention {
		color=lightgrey label="Dual Attention Mechanism" style=filled
		attn1 [label=<
    <table border="0">
        <tr><td><b>MultiheadAttention</b></td></tr>
        <tr><td>embed_dim=provider_num</td></tr>
        <tr><td>num_heads=1</td></tr>
    </table>>]
		k_proj [label="klinear
(Linear×3)"]
		v_proj [label="vlinear
(Linear×3)"]
	}
	subgraph cluster_t_attention {
		color=lightgrey label="Transposed Attention" style=filled
		t_attn [label=<
    <table border="0">
        <tr><td><b>MultiheadAttention</b></td></tr>
        <tr><td>embed_dim=task_num</td></tr>
        <tr><td>num_heads=1</td></tr>
    </table>>]
	}
	flatten [label=<
<table border="0">
    <tr><td><b>Flatten</b></td></tr>
    <tr><td>(task_num×provider_num → 1×t·p)</td></tr>
</table>>]
	linear [label=<
<table border="0">
    <tr><td><b>Linear Layers</b></td></tr>
    <tr><td>t·p → 2t·p → t·p</td></tr>
</table>>]
	subgraph cluster_lstm {
		color=lightgrey label="LSTM State Update" style=filled
		forget [label="Forget Gate
σ(W·[x, h_prev]+b)"]
		input_gate [label="Input Gate
σ(W·[x, h_prev]+b)"]
		cell_update [label="Cell State
c_t = f⊙c_{t-1} + i⊙g"]
		output_gate [label="Output Gate
o = σ(W·[x, h_prev]+b)"]
		hidden_state [label="New Hidden State
h_t = o⊙tanh(c_t)"]
	}
	output [label=<
<table border="0">
    <tr><td><b>Decision Layer</b></td></tr>
    <tr><td>Concat[pos, h_t, c_t]</td></tr>
    <tr><td>Output: 2×t·p logits</td></tr>
</table>>]
	input -> attn1
	attn1 -> t_attn
	t_attn -> flatten
	flatten -> linear
	linear -> forget
	linear -> input_gate
	linear -> output_gate
	forget -> cell_update [label="f⊙c_{t-1}"]
	input_gate -> cell_update [label="i⊙g"]
	cell_update -> hidden_state
	output_gate -> hidden_state [label="o⊙tanh(c_t)"]
	hidden_state -> output
	hidden_state -> forget [label=h_prev color="#666666" style=dashed]
	hidden_state -> input_gate [label=h_prev color="#666666" style=dashed]
	hidden_state -> output_gate [label=h_prev color="#666666" style=dashed]
	k_proj -> attn1 [label="Key Projection" style=dotted]
	v_proj -> attn1 [label="Value Projection" style=dotted]
	subgraph cluster_annotations {
		color=none
		dim1 [label=<
    <table border="0" cellborder="0">
        <tr><td>◀─ Input Dimensions ─▶</td></tr>
        <tr><td>Task Axis: {task_num}</td></tr>
        <tr><td>Provider Axis: {provider_num}</td></tr>
    </table>> shape=none]
		dim2 [label=<
    <table border="0" cellborder="0">
        <tr><td>State Dimensions:</td></tr>
        <tr><td>hidden_dim = {output_dim}</td></tr>
        <tr><td>cell_dim = {output_dim}</td></tr>
    </table>> shape=none]
	}
}
